{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "from shutil import copyfile\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {'year':'all', 'model':'warning'}\n",
    "response = requests.post('http://rdc28.cwb.gov.tw/TDB/ctrl_typhoon_list/get_typhoon_list_table', data=payload )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#找typhoon_id\n",
    "pattern = '<a class=\"typhoon_id\" value='\n",
    "deal_response = response.text\n",
    "is_find = 1\n",
    "ty_id = []\n",
    "rp_cut = response.text.replace('\\n','').replace('  ', '').split('</tr>')\n",
    "rp_info = []\n",
    "for i in rp_cut:\n",
    "    find_del_td = 1\n",
    "    while find_del_td:\n",
    "        find_del_td = re.search(\"<td width=.*?>\", i)#刪除多餘字串\n",
    "        if find_del_td:\n",
    "            i = i.replace(find_del_td.group(), '')\n",
    "    find_del_id = re.search('<a class=\"typhoon_id\" value=.*?>', i)\n",
    "    if find_del_id:\n",
    "        i = i.replace(find_del_id.group(), '').replace('</a>','')\n",
    "    i = i.replace('</br>', '</td>')\n",
    "    rp_info.append(i.replace('<tr>', '').split('</td>'))\n",
    "ty_info_re = []\n",
    "for j in rp_info: #移除一些路徑較為特殊的颱風\n",
    "    if len(j) == 14:\n",
    "        ty_info_re.append(j[0:13])\n",
    "ty_info = []\n",
    "for i in ty_info_re:\n",
    "    ty_info_temp = []\n",
    "    for idx, j in enumerate(i):\n",
    "        if idx != 5 and idx != 6:\n",
    "            j = j.replace(' ', '')\n",
    "            ty_info_temp.append(j)\n",
    "        else:\n",
    "            ty_info_temp.append(j)\n",
    "    ty_info.append(ty_info_temp)\n",
    "\n",
    "#欄位說明\n",
    "#年份, 編號, 中文名稱, 英文名稱, 侵臺路徑分類, 開始時間, 結束時間, 近臺強度, 中心最低氣壓, 中心最大風速, 最大7級暴風半徑, 最大10級暴風半徑, 警報發布數\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''整合並取得影像以及颱風其他測資'''\n",
    "img_dics = {}\n",
    "prop_dic = {}\n",
    "ty_dic_name = ''\n",
    "prop_list = ['year', 'number', 'c_name', 'en_name', 'invapath', 'alert_start', 'alert_end', 'intensity',\n",
    "                  'lowest_pressure', 'highest_pressure', 'large_seven_radius', 'large_ten_radius','alert_count']\n",
    "for idx, i in enumerate(ty_info):\n",
    "    headers = {\"X-Requested-With\":\"XMLHttpRequest\"}\n",
    "    payload = {'typhoon_year':i[0], 'typhoon_name':i[3], 'typhoon_type':'Satellite'}\n",
    "    img_response = requests.post('http://rdc28.cwb.gov.tw/TDB/ctrl_typhoon_list/rtn_typhoon_product', data=payload, headers=headers)\n",
    "    img_str = img_response.text.replace('\\n' , '')\n",
    "    if len(img_str) != 0:\n",
    "        img_dic = json.loads(img_str) #將回送回來的資料用json儲存\n",
    "        ty_dic_name = str(i[0]) + '_' + str(i[3]) #颱風的dictionary名稱\n",
    "        img_dics.update({ty_dic_name:img_dic}) #合併所有颱風資料到一個大dic        \n",
    "        prop_dic = [{prop: value} for prop, value in zip(prop_list, i)] #把颱風的數據存到每個颱風內的第一層字典裡\n",
    "        for prop in prop_dic:\n",
    "            img_dics[ty_dic_name].update(prop)\n",
    "\n",
    "#     r = requests.get('http://rdc28.cwb.gov.tw/TDB/data/Indiv/2016/MERANTI/OBS/Satellite/Satellite_IR1_FDK.201609092350.jpg?1511463696739')\n",
    "#     with open('test.jpg', 'wb') as f:\n",
    "#         f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''自動化生成颱風概況網站網址, 判斷海上陸上颱風警報個數，並取出發布時間和解除時間, 存入字典的第一層'''\n",
    "for i in ty_info:\n",
    "    info_address = 'http://rdc28.cwb.gov.tw/TDB/ctrl_typhoon_list/redirect2detail?typhoonId=' + i[1]\n",
    "    r = requests.get(info_address)\n",
    "    r.encoding = 'unicode_escape'\n",
    "    announce_time_text = r.text.replace('\\n','').split('class=&quot;td_title&quot;&gt;')[5].split('&lt;\\/td&gt;')[1]\n",
    "    release_time_text = r.text.replace('\\n','').split('class=&quot;td_title&quot;&gt;')[6].split('&lt;\\/td&gt;')[1]\n",
    "    ty_dic_name = str(i[0]) + '_' + str(i[3])\n",
    "    time.sleep(0.1)\n",
    "    if ty_dic_name in img_dics.keys():\n",
    "        if announce_time_text.count('海上') == 1 and announce_time_text.count('陸上') == 1:\n",
    "            sea_announce_time = announce_time_text[announce_time_text.find('海上') + 3:announce_time_text.find('海上') + 19]\n",
    "            land_announce_time = announce_time_text[announce_time_text.find('陸上') + 3:announce_time_text.find('陸上') + 19]\n",
    "            sea_release_time = release_time_text[release_time_text.find('海上') + 3:release_time_text.find('海上') + 19]\n",
    "            land_release_time = release_time_text[release_time_text.find('陸上') + 3:release_time_text.find('陸上') + 19]\n",
    "            img_dics[ty_dic_name].update({'sea_announce_time':sea_announce_time})\n",
    "            img_dics[ty_dic_name].update({'land_announce_time':land_announce_time})\n",
    "            img_dics[ty_dic_name].update({'sea_release_time':sea_release_time})\n",
    "            img_dics[ty_dic_name].update({'land_release_time':land_release_time})\n",
    "\n",
    "'''取得颱風個欄位名稱'''\n",
    "# print(r.text.replace('\\n','').split('class=&quot;td_title&quot;&gt;')[5].split('&lt;\\/td&gt;')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('typhoon_img_info.json', 'w') as outfile:\n",
    "    json.dump(img_dics, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "強颱的個數: 35\n",
      "中颱的個數: 70\n",
      "輕颱的個數: 39\n",
      "有發布陸上颱風警報且有東亞紅外線雲圖的颱風個數: 144\n"
     ]
    }
   ],
   "source": [
    "'''取出颱風從海上颱風警報到陸上颱風警報發布期間的雲圖資料'''\n",
    "\n",
    "land_alert_ty_count = 0\n",
    "high_ty_count = 0\n",
    "mid_ty_count = 0\n",
    "low_ty_count = 0\n",
    "ty_imgs_saved_dir = 'E:/Typhoon/'\n",
    "stop_flag = False\n",
    "for ty_name in img_dics:\n",
    "    if 'land_announce_time' in img_dics[ty_name]: #判斷這個颱風有沒有陸上颱風警報\n",
    "        subindex_list = []\n",
    "        subdata_disc = img_dics[ty_name]['Satellite']['subdatatype']\n",
    "        for subindex in subdata_disc:\n",
    "            subindex_list.append(subindex['name'])\n",
    "        if '東亞紅外線雲圖' in subindex_list: #判斷這個颱風有沒有東亞紅外線雲圖\n",
    "            start_time = img_dics[ty_name]['sea_announce_time']\n",
    "            end_time = img_dics[ty_name]['land_announce_time']\n",
    "#             print(ty_name)\n",
    "            if img_dics[ty_name]['intensity'] == '強烈':\n",
    "                high_ty_count += 1\n",
    "                new_end_time = datetime.strptime(end_time, \"%Y-%m-%d %H:%M\")\n",
    "                new_end_time += timedelta(hours=12)\n",
    "                end_time = new_end_time.strftime(\"%Y-%m-%d %H:%M\")\n",
    "            elif img_dics[ty_name]['intensity'] == '中度':\n",
    "                mid_ty_count += 1\n",
    "            else:\n",
    "                low_ty_count += 1\n",
    "            for img_file in subdata_disc[subindex_list.index('東亞紅外線雲圖')]['sets']:\n",
    "                if int(img_dics[ty_name]['year']) >= 1995 and int(img_dics[ty_name]['year']) <= 2015: #限定年份區間\n",
    "                    if img_file[0] >= start_time  and img_file[0] <= end_time: #限定時間段\n",
    "                        ty_img_saved_path = ty_imgs_saved_dir + ty_name + '/' + '東亞紅外線雲圖/' + img_file[1]\n",
    "                        new_save_dir = ty_imgs_saved_dir + 'take_out/' + img_dics[ty_name]['intensity'] #存入強度資料夾\n",
    "                        if not os.path.isdir(new_save_dir): #建立新分類的資料夾\n",
    "                            os.mkdir(new_save_dir)\n",
    "                        new_save_path = new_save_dir + '/' + img_file[1]           \n",
    "                        copyfile(ty_img_saved_path, new_save_path)                    \n",
    "            land_alert_ty_count += 1\n",
    "print('強颱的個數: ' + str(high_ty_count))\n",
    "print('中颱的個數: ' + str(mid_ty_count))\n",
    "print('輕颱的個數: ' + str(low_ty_count))\n",
    "print('有發布陸上颱風警報且有東亞紅外線雲圖的颱風個數: ' + str(land_alert_ty_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TALIM\n",
      "GUCHOL\n",
      "HATO\n",
      "HAITANG\n",
      "NESAT\n",
      "AERE\n",
      "MEGI\n",
      "MALAKAS\n",
      "MERANTI\n",
      "NEPARTAK\n",
      "DUJUAN\n",
      "GONI\n",
      "SOUDELOR\n",
      "LINFA\n",
      "CHAN-HOM\n",
      "NOUL\n",
      "FUNG-WONG\n",
      "MATMO\n",
      "HAGIBIS\n",
      "FITOW\n",
      "USAGI\n",
      "KONG-REY\n",
      "TRAMI\n",
      "CIMARON\n",
      "SOULIK\n",
      "JELAWAT\n",
      "TEMBIN\n",
      "KAI-TAK\n",
      "HAIKUI\n",
      "SAOLA\n",
      "DOKSURI\n",
      "TALIM\n",
      "NANMADOL\n",
      "MUIFA\n",
      "MEARI\n",
      "SONGDA\n",
      "AERE\n",
      "MEGI\n",
      "FANAPI\n",
      "MERANTI\n",
      "NAMTHEUN\n",
      "LIONROCK\n",
      "PARMA\n",
      "MORAKOT\n",
      "MOLAVE\n",
      "LINFA\n",
      "JANGMI\n",
      "HAGUPIT\n",
      "SINLAKU\n",
      "NURI\n",
      "FUNG-WONG\n",
      "KALMAEGI\n",
      "MITAG\n",
      "KROSA\n",
      "WIPHA\n",
      "SEPAT\n",
      "WUTIP\n",
      "PABUK\n",
      "SHANSHAN\n",
      "BOPHA\n",
      "SAOMAI\n",
      "KAEMI\n",
      "BILIS\n",
      "EWINIAR\n",
      "CHANCHU\n",
      "LONGWANG\n",
      "DAMREY\n",
      "KHANUN\n",
      "TALIM\n",
      "SANVU\n",
      "MATSA\n",
      "HAITANG\n",
      "NANMADOL\n",
      "NOCK-TEN\n",
      "MEARI\n",
      "HAIMA\n",
      "AERE\n",
      "RANANIM\n",
      "KOMPASU\n",
      "MINDULLE\n",
      "CONSON\n",
      "MELOR\n",
      "DUJUAN\n",
      "KROVANH\n",
      "VAMCO\n",
      "MORAKOT\n",
      "IMBUDO\n",
      "SOUDELOR\n",
      "NANGKA\n",
      "KUJIRA\n",
      "SINLAKU\n",
      "NAKRI\n",
      "RAMMASUN\n",
      "HAIYAN\n",
      "LEKIMA\n",
      "NARI\n",
      "TORAJI\n",
      "YUTU\n",
      "TRAMI\n",
      "UTOR\n",
      "CHEBI\n",
      "CIMARON\n",
      "BEBINCA\n",
      "XANGSANE\n",
      "YAGI\n",
      "BOPHA\n",
      "PRAPIROON\n",
      "BILIS\n",
      "KAI-TAK\n",
      "DAN\n",
      "SAM\n",
      "MAGGIE\n",
      "BABS\n",
      "ZEB\n",
      "YANNI\n",
      "OTTO\n",
      "NICHOLE\n",
      "IVAN\n",
      "CASS\n",
      "AMBER\n",
      "WINNIE\n",
      "ZANE\n",
      "VIOLET\n",
      "SALLY\n",
      "LISA\n",
      "HERB\n",
      "GLORIA\n",
      "CAM\n",
      "RYAN\n",
      "KENT\n",
      "JANIS\n",
      "HELEN\n",
      "GARY\n",
      "DEANNA\n",
      "SETH\n",
      "GLADYS\n",
      "FRED\n",
      "DOUG\n",
      "CAITLIN\n",
      "ABE\n",
      "YANCY\n",
      "TASHA\n",
      "TED\n",
      "POLLY\n",
      "OMAR\n",
      "MARK\n",
      "BOBBIE\n",
      "SETH\n",
      "RUTH\n",
      "NAT\n",
      "MIREILLE\n",
      "ELLIE\n",
      "BRENDAN\n",
      "AMY\n",
      "ED\n",
      "DOT\n",
      "BECKY\n",
      "ABE\n",
      "YANCY\n",
      "ROBYN\n",
      "PERCY\n",
      "OFELIA\n",
      "MARIAN\n",
      "ANGELA\n",
      "VERA\n",
      "SARAH\n",
      "RUBY\n",
      "PAT\n",
      "ODESSA\n",
      "NELSON\n",
      "LEE\n",
      "KIT\n",
      "WARREN\n",
      "SUSAN\n",
      "LYNN\n",
      "GERALD\n",
      "DINAH\n",
      "CARY\n",
      "ALEX\n",
      "VERNON\n",
      "THELMA\n",
      "ELLEN\n",
      "ABBY\n",
      "WAYNE\n",
      "VERA\n",
      "SARAH\n",
      "PEGGY\n",
      "NANCY\n",
      "BRENDA\n",
      "VAL\n",
      "TESS\n",
      "PAT\n",
      "NELSON\n",
      "JEFF\n",
      "HAL\n",
      "BILL\n",
      "WYNNE\n",
      "FORREST\n",
      "ELLEN\n",
      "ABBY\n",
      "WAYNE\n",
      "NANCY\n",
      "KEN\n",
      "FAYE\n",
      "DOT\n",
      "CECIL\n",
      "ANDY\n",
      "TESS\n",
      "IRMA\n",
      "GAY\n",
      "CLARA\n",
      "AGNES\n",
      "MAURY\n",
      "JUNE\n",
      "IKE\n"
     ]
    }
   ],
   "source": [
    "'''自動化下載衛星雲圖'''\n",
    "for name in img_dics.keys(): \n",
    "    print(img_dics[name]['en_name'])\n",
    "    if not os.path.isdir(name):#建立某颱風的資料夾\n",
    "            os.mkdir(name)\n",
    "    for img_style in img_dics[name]['Satellite']['subdatatype']:\n",
    "        img_style_name = img_style['name']\n",
    "        img_path = name + '/' + img_style_name\n",
    "        if not os.path.isdir(img_path): #建立某類型的雲圖資料夾\n",
    "            os.mkdir(img_path)\n",
    "        img_sets = img_style['sets']\n",
    "        img_prefix = 'http://rdc28.cwb.gov.tw/TDB/data/Indiv/' + img_dics[name]['year'] + '/' + img_dics[name]['en_name'] + '/OBS/Satellite/' \n",
    "        for img_idx in img_sets:\n",
    "            img_address = img_prefix + img_idx[1]\n",
    "            img_r = requests.get(img_address)\n",
    "            with open(img_path + '/' + img_idx[1], 'wb') as f:\n",
    "                f.write(img_r.content)\n",
    "        time.sleep(5)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "#['GROUP', 'c_name', 'title', 'caption_has_datetime', 'subdatatype', 'e_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EPcompCrawler():\n",
    "    \n",
    "    BASE_URL = 'http://www.piano-e-competition.com/'\n",
    "\n",
    "    def __init__(self, sleep_time=0.1, log=True):\n",
    "        self.sleep_time = sleep_time\n",
    "        self.log = log\n",
    "        \n",
    "    def _log_print(self, log, quite=False):\n",
    "        if not quite:\n",
    "            print(log)\n",
    "\n",
    "        if self.log:\n",
    "            with open(\"log.txt\", \"a\") as f:\n",
    "                print(log, file=f)\n",
    "def _get_header():\n",
    "# POST /TDB/ctrl_typhoon_list/get_typhoon_list_table/ HTTP/1.1\n",
    "    header = {\n",
    "'Host': 'rdc28.cwb.gov.tw',\n",
    "'Connection': 'keep-alive',\n",
    "'Content-Length': '22',\n",
    "'Accept': 'text/plain, */*; q=0.01',\n",
    "# 'Origin': 'http://rdc28.cwb.gov.tw',\n",
    "'X-Requested-With': 'XMLHttpRequest',\n",
    "'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36',\n",
    "'Content-Type': 'application/x-www-form-urlencoded',\n",
    "'Accept-Encoding': 'gzip, deflate',\n",
    "'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7'}\n",
    "# 'Cookie': 'PHPSESSID=vvecuo9aumnaa6hrf2fquu9lr6; ci_session=a%3A5%3A%7Bs%3A10%3A%22session_id%22%3Bs%3A32%3A%2277ea4e059cb949d97e23b99c69e8ffe7%22%3Bs%3A10%3A%22ip_address%22%3Bs%3A14%3A%22210.69.218.230%22%3Bs%3A10%3A%22user_agent%22%3Bs%3A114%3A%22Mozilla%2F5.0+%28Windows+NT+10.0%3B+Win64%3B+x64%29+AppleWebKit%2F537.36+%28KHTML%2C+like+Gecko%29+Chrome%2F62.0.3202.94+Safari%2F537.36%22%3Bs%3A13%3A%22last_activity%22%3Bi%3A1511449596%3Bs%3A9%3A%22user_data%22%3Bs%3A0%3A%22%22%3B%7Dc781ff204174d900932cc60821283866; TS01b0fe7f=0107dddfefb4158b847cf1d05483c6415c37bb75c11ff13b2154e507454d41d8f3d81a64830a94d79d1004eb315364ea5f61f284a1428ef062bc39e9607e4f675696a79089'}\n",
    "\n",
    "    return header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70466\n"
     ]
    }
   ],
   "source": [
    "headers = {\"X-Requested-With\":\"XMLHttpRequest\"}\n",
    "payload = {'typhoon_year':'2013', 'typhoon_name':'TRAMI', 'typhoon_type':'Satellite'}\n",
    "img_response = requests.post('http://rdc28.cwb.gov.tw/TDB/ctrl_typhoon_list/rtn_typhoon_product', data=payload, headers=headers)\n",
    "img_str = img_response.text.replace('\\n' , '')\n",
    "print(len(img_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'year': 1},\n",
       " {'number': 2},\n",
       " {'c_name': 3},\n",
       " {'en_name': 4},\n",
       " {'invapath': 5},\n",
       " {'alert_start': 6},\n",
       " {'alert_end': 7},\n",
       " {'intensity': 8},\n",
       " {'lowest_pressure': 9},\n",
       " {'highest_pressure': 10}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_name_www = ['year', 'number', 'c_name', 'en_name', 'invapath', 'alert_start', 'alert_end', 'intensity',\n",
    "                  'lowest_pressure', 'highest_pressure']\n",
    "oxo_list = [1,2,3,4,5,6,7,8,9,10]\n",
    "[{prop: value} for prop, value in zip(prop_name_www, oxo_list)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
